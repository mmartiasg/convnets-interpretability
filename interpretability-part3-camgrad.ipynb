{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE = (256, 256)\n",
    "CHANNEL = 3\n",
    "MODEL_NAME = \"model3\"\n",
    "\n",
    "# IMAGE_PATH = \"./datasets/test/dora-over-armary-close.jpg\"\n",
    "# IMAGE_PATH = \"./datasets/test/manydogs.jpeg\"\n",
    "# IMAGE_PATH = \"./datasets/test/meow.jpg\"\n",
    "# IMAGE_PATH = \"./datasets/test/panda.jpg\"\n",
    "IMAGE_PATH = \"./datasets/test/dora_stares_at_you.jpg\"\n",
    "\n",
    "IMAGE_NAME = IMAGE_PATH.split(\"/\")[3]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This procedure consist on obtaining how important the ontributions of each of the channels when finding the class the object belongs to.\n",
    "\n",
    "With this procedure we are able to understand which parts of the images producce the most amount of activations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(f\"./checkpoints/{MODEL_NAME}/\")\n",
    "\n",
    "model = tf.keras.applications.ResNet50(include_top=True)\n",
    "# model = tf.keras.applications.VGG19(include_top=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: llevar a lib aparte\n",
    "\n",
    "def get_convs_layers(model):\n",
    "    outputs=[]\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, (tf.keras.layers.Conv2D, tf.keras.layers.MaxPool2D)):\n",
    "            layer.trainable=False\n",
    "            outputs.append(layer)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_layer_conv_output = get_convs_layers(model)[-1].output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_layer_conv_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_conv_model = tf.keras.Model(inputs=model.input, outputs=last_layer_conv_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[-4:][0].output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We get a model that will take the output of the last convolutional layer and produce a prediction\n",
    "classification_model_input = tf.keras.Input(shape=last_conv_model.output.shape[1:])\n",
    "\n",
    "x = classification_model_input\n",
    "\n",
    "classification_layers = model.layers[-2:]\n",
    "#Build the graph from the output of the last model to the classification layer model\n",
    "for layer in classification_layers:\n",
    "    x = layer(x)\n",
    "\n",
    "classification_model_output = tf.keras.Model(inputs=classification_model_input, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_model_output.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load a sample image\n",
    "\n",
    "INPUT_SHAPE = model.input.shape[1:-1]\n",
    "\n",
    "image = tf.keras.utils.load_img(IMAGE_PATH, color_mode=\"rgb\" if CHANNEL==3 else \"grayscale\", target_size=(INPUT_SHAPE))\n",
    "image_vector = tf.keras.utils.img_to_array(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_vector/=256\n",
    "plt.imshow(image_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_vector = np.expand_dims(image_vector, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    last_conv_activation = last_conv_model(image_vector)\n",
    "    tape.watch(last_conv_activation)\n",
    "    classfication_output = classification_model_output(last_conv_activation)\n",
    "    top_pred_index = tf.argmax(classfication_output[0])\n",
    "    top_class_channel = classfication_output[:, top_pred_index]\n",
    "\n",
    "activation_gradient = tape.gradient(top_class_channel, last_conv_activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient corresponding to the last convolutional layer when applied to the classification output\n",
    "\n",
    "activation_gradient[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# activation_gradient = activation_gradient[0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average on for channel\n",
    "# average_gradient_activation = np.average(activation_gradient, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average_gradient_activation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pooling chanel importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pooled_grads = tf.reduce_mean(activation_gradient, axis=(0, 1, 2)).numpy()\n",
    "last_conv_activation = last_conv_activation.numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pooled_grads.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weight the values from the last activation \n",
    "for i in range(pooled_grads.shape[-1]):\n",
    "    last_conv_activation[:, :, i] *= pooled_grads[i]\n",
    "\n",
    "#get the average value per channel\n",
    "heathmap = np.mean(last_conv_activation, axis=-1)\n",
    "\n",
    "#remove negative values\n",
    "heathmap = np.maximum(heathmap, 0)\n",
    "\n",
    "# scale values of the heatmap to keep it between 0 - 1\n",
    "heathmap /= np.max(heathmap)\n",
    "\n",
    "plt.imshow(heathmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.cm as cm\n",
    "\n",
    "# jet = cm.get_cmap(\"jet\")\n",
    "\n",
    "# jet_colors = jet(np.arange(256))[:, :CHANNEL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm\n",
    "\n",
    "image = tf.keras.utils.load_img(IMAGE_PATH, color_mode=\"rgb\" if CHANNEL==3 else \"grayscale\")\n",
    "image = tf.keras.utils.img_to_array(image)\n",
    "\n",
    "heathmap = np.uint(255 * heathmap)\n",
    "jet = cm.get_cmap(\"jet\")\n",
    "jet_colors = jet(np.arange(256))[:, :CHANNEL]\n",
    "jet_heatmap = jet_colors[heathmap]\n",
    "\n",
    "jet_heatmap = tf.keras.utils.array_to_img(jet_heatmap)\n",
    "jet_heatmap = jet_heatmap.resize((image.shape[1], image.shape[0]))\n",
    "jet_heatmap = tf.keras.utils.img_to_array(jet_heatmap)\n",
    "\n",
    "# Combine heatmal with the image superpose both\n",
    "superimpose_img = jet_heatmap * 0.6 + image\n",
    "superimpose_img = tf.keras.utils.array_to_img(superimpose_img)\n",
    "\n",
    "save_path = f\"./heatmaps-part3/{IMAGE_NAME}_{MODEL_NAME}.jpg\"\n",
    "superimpose_img.save(save_path)\n",
    "\n",
    "plt.imshow(superimpose_img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfm1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
