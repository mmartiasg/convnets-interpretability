{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 of interpretability of a Convnet model\n",
    "\n",
    "\n",
    "In this case the idea now is to plot what the filters see when they activate at their highest level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.autonotebook import tqdm\n",
    "import math"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load the 3 models we already've trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = tf.keras.models.load_model(\"./checkpoints/model1/\")\n",
    "\n",
    "model2 = tf.keras.models.load_model(\"./checkpoints/model2/\")\n",
    "\n",
    "model3 = tf.keras.models.load_model(\"./checkpoints/esp32/\")\n",
    "\n",
    "# pretrained models\n",
    "# model_pretrained = tf.keras.applications.InceptionV3(include_top=False)\n",
    "model_pretrained = tf.keras.applications.ResNet50(include_top=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First step build a loss function\n",
    "\n",
    "The idea is to maximize the activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tensor = tf.expand_dims(tf.random.uniform(minval=0.4, maxval=0.6, shape=(256, 256, 3)), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reduce_mean(test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reduce_mean(tf.math.rsqrt(tf.math.reduce_euclidean_norm(test_tensor, axis=2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.math.reduce_euclidean_norm(tf.reduce_mean(test_tensor, axis=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(activation):\n",
    "    \"\"\"\n",
    "        initial_random_image: initial random image made to max out the activation of the filter.\n",
    "        prediction: output of the filter's activation.\n",
    "        Squared Error\n",
    "\n",
    "        # Trying to maximize the activations average.\n",
    "    \"\"\"\n",
    "\n",
    "    return tf.reduce_mean(activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproces_img(image_output):\n",
    "\n",
    "    filter_patern = image_output.copy()\n",
    "\n",
    "    mean = filter_patern.mean()\n",
    "    std = filter_patern.std()\n",
    "\n",
    "    filter_patern -= mean\n",
    "    filter_patern /= std\n",
    "\n",
    "    filter_patern *= 64\n",
    "    filter_patern += 128\n",
    "    \n",
    "    filter_patern = np.clip(filter_patern, 0, 255).astype(\"uint8\")\n",
    "\n",
    "    #Center image\n",
    "    return filter_patern[25:-25, 25:-25, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_convs_layers(model):\n",
    "    outputs=[]\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, (tf.keras.layers.Conv2D, tf.keras.layers.MaxPool2D)):\n",
    "            layer.trainable=False\n",
    "            outputs.append(layer)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_filters(model_name, layer_name, all_images, image_shape=(256, 256)):       \n",
    "    margin = 5\n",
    "    c = 4\n",
    "    r = math.ceil(len(all_images)/c)\n",
    "\n",
    "    cropped_width = image_shape[0]-25*2\n",
    "    cropped_height = image_shape[1]-25*2\n",
    "\n",
    "    width = r * cropped_width + (r-1) * margin\n",
    "    height = c * cropped_height + (c-1) * margin\n",
    "\n",
    "    stitched_filters = np.zeros((width, height, 3))\n",
    "\n",
    "    #rows\n",
    "    for i in tqdm(range(r)):\n",
    "        for j in range(c):\n",
    "            image = all_images[i * c +j]\n",
    "\n",
    "            row_start= (cropped_width + margin) * i\n",
    "            row_end = (cropped_height + margin) * i + cropped_width\n",
    "            column_start = (cropped_height + margin) * j\n",
    "            column_end = (cropped_height + margin) * j + cropped_height\n",
    "\n",
    "            stitched_filters[row_start: row_end, column_start: column_end, :] = image\n",
    "\n",
    "    tf.keras.utils.save_img(f\"./part2-filters/{model_name}/{layer_name}.png\", stitched_filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def optimize_step(feature_extractor_model, image, filter_index, lr):\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(image)\n",
    "\n",
    "        activation = feature_extractor_model(image)\n",
    "        activation = activation[:, 2:-2, 2:-2, filter_index]\n",
    "\n",
    "        loss_value = loss(activation)\n",
    "\n",
    "    gradients = tape.gradient(loss_value, image)\n",
    "    gradients = tf.math.l2_normalize(gradients)\n",
    "\n",
    "    image += gradients*lr\n",
    "\n",
    "    return image, loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model3\n",
    "\n",
    "filter_index = 0\n",
    "sample_layer = model.get_layer(\"2nd_conv_3x3\")\n",
    "feature_extractor_model = tf.keras.Model(inputs=model.input, outputs=sample_layer.output)\n",
    "\n",
    "lr=10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_layer.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_layer.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = sample_layer.weights[0][:, :, 0, 7]\n",
    "\n",
    "kernel *= 64\n",
    "kernel += 128\n",
    "\n",
    "kernel = np.array(np.clip(kernel, a_min=0, a_max=255), dtype=np.uint8)\n",
    "\n",
    "print(kernel)\n",
    "\n",
    "plt.imshow(kernel)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import gc\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "image_shape_list = [(256, 256, 3), (256, 256, 3), (96, 96, 1), (299, 299, 3)]\n",
    "\n",
    "models=[model1, model2, model3, model_pretrained]\n",
    "models_name = [\"model_1_new_version\", \"model_2_new_version\", \"model_3_new_version\", \"model_resnet50\"]\n",
    "\n",
    "epochs = 500\n",
    "learning_rate = 10.\n",
    "\n",
    "for model_name, model, image_shape in zip(models_name, models, image_shape_list):\n",
    "    print(f\"Model : {model_name}\")\n",
    "\n",
    "    if not os.path.exists(f\"part2-filters/{model_name}/\"):\n",
    "        os.mkdir(f\"part2-filters/{model_name}/\")\n",
    "    else:\n",
    "        shutil.rmtree(f\"part2-filters/{model_name}/\")\n",
    "        os.mkdir(f\"part2-filters/{model_name}/\")\n",
    "\n",
    "    for layer in get_convs_layers(model):\n",
    "        feature_extractor_model = tf.keras.Model(inputs=model.input, outputs=layer.output)\n",
    "        images = []\n",
    "\n",
    "        filters_count = layer.output.shape[-1]\n",
    "\n",
    "        for filter_index in range(filters_count):\n",
    "            # noisy_image = tf.expand_dims(tf.random.uniform(minval=0.4, maxval=0.6, shape=image_shape), axis=0)\n",
    "            noisy_image = tf.expand_dims(tf.random.normal(shape=image_shape), axis=0)\n",
    "\n",
    "            for epoch in range(epochs):\n",
    "                noisy_image, loss_value = optimize_step(feature_extractor_model, noisy_image, filter_index, learning_rate)\n",
    "\n",
    "            images.append(preproces_img(noisy_image.numpy()[0].copy()))\n",
    "        \n",
    "        del feature_extractor_model\n",
    "        tf.keras.backend.clear_session()\n",
    "        gc.collect()\n",
    "\n",
    "        print_filters(model_name=model_name, layer_name=layer.name, all_images=images, image_shape=image_shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfm1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
